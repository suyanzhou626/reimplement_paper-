{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AttaNet: Attention-Augmented Network for Fast and Accurate Scene Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "official pytorch: https://github.com/songqi-github/AttaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T08:11:26.695107Z",
     "start_time": "2021-05-14T08:11:26.692011Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T08:11:27.154029Z",
     "start_time": "2021-05-14T08:11:26.993631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class SAM(nn.Module):\n",
    "    def __init__(self, in_chans=512, h=64, w=64, r=8):\n",
    "        super(SAM, self).__init__()\n",
    "        \n",
    "        self.conv2d = nn.Conv2d(in_chans, in_chans, kernel_size=1)\n",
    "        \n",
    "        self.conv2dq = nn.Conv2d(in_chans, in_chans//r, kernel_size=1)\n",
    "        self.conv2dk = nn.Conv2d(in_chans, in_chans//r, kernel_size=1)\n",
    "        \n",
    "        self.adapavgpoolk = nn.AdaptiveAvgPool2d((h,1))\n",
    "        self.adapavgpoolv = nn.AdaptiveAvgPool2d((1,w))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        #\n",
    "        V = self.conv2d(x)\n",
    "        Q = self.conv2dq(x)\n",
    "        K = self.conv2dk(x)\n",
    "        \n",
    "        #\n",
    "        Q = Q.contiguous().view(b,-1,h*w)\n",
    "        K = self.adapavgpoolk(K).squeeze(-1)\n",
    "        #\n",
    "        A = torch.einsum('bcn,bcw->bnw',Q,K)\n",
    "        A = F.softmax(A, dim=1)\n",
    "        #\n",
    "        V = self.adapavgpoolv(V).squeeze(-2)\n",
    "        #\n",
    "        out_F = torch.einsum('bnw,bcw->bcn',A,V).contiguous().view(b,-1,h,w) + x\n",
    "        return out_F\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    inp = torch.randn(2, 512, 64, 64)\n",
    "    module = SAM()\n",
    "    out = module(inp)\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T08:57:44.385189Z",
     "start_time": "2021-05-14T08:57:44.372130Z"
    }
   },
   "outputs": [],
   "source": [
    "# official implement\n",
    "class StripAttentionModule(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, *args, **kwargs):\n",
    "        super(StripAttentionModule, self).__init__()\n",
    "        self.conv1 = ConvBNReLU(in_chan, 64, ks=1, stride=1, padding=0)\n",
    "        self.conv2 = ConvBNReLU(in_chan, 64, ks=1, stride=1, padding=0)\n",
    "        self.conv3 = ConvBNReLU(in_chan, out_chan, ks=1, stride=1, padding=0)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = self.conv1(x)\n",
    "        batchsize, c_middle, h, w = q.size()\n",
    "        q = F.avg_pool2d(q, [h, 1])\n",
    "        q = q.view(batchsize, c_middle, -1).permute(0, 2, 1)\n",
    "\n",
    "        k = self.conv2(x)\n",
    "        k = k.view(batchsize, c_middle, -1)\n",
    "        attention_map = torch.bmm(q, k)\n",
    "        attention_map = self.softmax(attention_map)\n",
    "\n",
    "        v = self.conv3(x)\n",
    "        c_out = v.size()[1]\n",
    "        v = F.avg_pool2d(v, [h, 1])\n",
    "        v = v.view(batchsize, c_out, -1)\n",
    "\n",
    "        augmented_feature_map = torch.bmm(v, attention_map)\n",
    "        augmented_feature_map = augmented_feature_map.view(batchsize, c_out, h, w)\n",
    "        out = x + augmented_feature_map\n",
    "        return out\n",
    "\n",
    "    def init_weight(self):\n",
    "        for ly in self.children():\n",
    "            if isinstance(ly, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
    "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
    "\n",
    "    def get_params(self):\n",
    "        wd_params, nowd_params = [], []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "                wd_params.append(module.weight)\n",
    "                if not module.bias is None:\n",
    "                    nowd_params.append(module.bias)\n",
    "            elif isinstance(module, BatchNorm2d):\n",
    "                nowd_params += list(module.parameters())\n",
    "        return wd_params, nowd_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T08:38:57.029349Z",
     "start_time": "2021-05-14T08:38:56.168524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class AFM(nn.Module):\n",
    "    def __init__(self, in_chans_i=512, in_chans_j=1024):\n",
    "        super(AFM, self).__init__()\n",
    "        \n",
    "        self.conv3x3a = nn.Conv2d(\n",
    "            in_chans_i, \n",
    "            in_chans_i, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "            )\n",
    "        \n",
    "        self.conv3x3b = nn.Conv2d(\n",
    "            in_chans_j, \n",
    "            in_chans_i, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "            )\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_chans_i*2, in_chans_i, kernel_size=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_chans_i, in_chans_i, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, f_i, f_j):\n",
    "\n",
    "        _f_i = F.interpolate(\n",
    "            f_i, \n",
    "            size=f_j.shape[2:], \n",
    "            mode='bilinear', \n",
    "            align_corners=True\n",
    "            )\n",
    "        f_i = self.conv3x3a(f_i)\n",
    "        _f_j = self.conv3x3b(f_j)\n",
    "\n",
    "        f = torch.cat((_f_i, _f_j), dim=1)\n",
    "        alpha = self.conv(f)\n",
    "        out_f_i =  torch.mul(alpha, f_i)\n",
    "        \n",
    "        out_f_j = torch.mul(1-alpha, _f_j)\n",
    "        \n",
    "        out_f_i = F.interpolate(\n",
    "            out_f_i, \n",
    "            size=f_j.shape[2:], \n",
    "            mode='bilinear', \n",
    "            align_corners=True\n",
    "            )\n",
    "\n",
    "        out = out_f_i + out_f_j\n",
    "        return out\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    f_i = torch.randn(2, 512, 128, 128)\n",
    "    f_j = torch.randn(2, 1024, 64, 64)\n",
    "    \n",
    "    module = AFM()\n",
    "    out = module(f_i, f_j)\n",
    "    print(out.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# official implement\n",
    "class AttentionFusionModule(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, *args, **kwargs):\n",
    "        super(AttentionFusionModule, self).__init__()\n",
    "        self.conv = ConvBNReLU(in_chan, out_chan, ks=1, stride=1, padding=0)\n",
    "        self.conv_atten = nn.Conv2d(out_chan, out_chan, kernel_size=1, bias=False)\n",
    "        self.bn_atten = BatchNorm2d(out_chan)\n",
    "        self.sigmoid_atten = nn.Sigmoid()\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def forward(self, feat16, feat32):\n",
    "        feat32_up = F.interpolate(feat32, feat16.size()[2:], mode='nearest')\n",
    "        fcat = torch.cat([feat16, feat32_up], dim=1)\n",
    "        feat = self.conv(fcat)\n",
    "\n",
    "        atten = F.avg_pool2d(feat, feat.size()[2:])\n",
    "        atten = self.conv_atten(atten)\n",
    "        atten = self.bn_atten(atten)\n",
    "        atten = self.sigmoid_atten(atten)\n",
    "        return atten\n",
    "\n",
    "    def init_weight(self):\n",
    "        for ly in self.children():\n",
    "            if isinstance(ly, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(ly.weight, a=1)\n",
    "                if not ly.bias is None: nn.init.constant_(ly.bias, 0)\n",
    "\n",
    "    def get_params(self):\n",
    "        wd_params, nowd_params = [], []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "                wd_params.append(module.weight)\n",
    "                if not module.bias is None:\n",
    "                    nowd_params.append(module.bias)\n",
    "            elif isinstance(module, BatchNorm2d):\n",
    "                nowd_params += list(module.parameters())\n",
    "        return wd_params, nowd_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
